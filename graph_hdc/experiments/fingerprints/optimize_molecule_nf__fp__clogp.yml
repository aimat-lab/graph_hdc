# PyComex configuration file for CLogP optimization on AqSolDB using Fingerprints with Normalizing Flow
pycomex: true

extend: optimize_molecule_nf__fp.py

include: mixin_clogp.py

name: optimize_nf_fp_aqsoldb_clogp

description: |
  Fingerprint-based molecular representation optimization with normalizing flow
  constraints for CLogP prediction on AqSolDB.

  This experiment uses the AqSolDB dataset structure but optimizes for CLogP
  (calculated LogP) values computed via RDKit's Crippen method instead of the
  default logS (aqueous solubility) values.

  Key differences from optimize_molecule__fp.py:
  - Single model (no ensemble) for faster training
  - No PCA optimization (works in original fingerprint space)
  - Normalizing flow constraint to keep optimization in-distribution
  - Simpler architecture focused on flow-guided optimization

  The mixin_clogp.py calculates CLogP values for all molecules and replaces the
  graph_labels, which are then used as the target property for optimization.

  Morgan fingerprints with radius=3 provide a good balance between local and
  global structural information for LogP prediction.

parameters:
  SEED: null

  DATASET_NAME: "aqsoldb"
  DATASET_NAME_ID: "aqsoldb_clogp_nf"

  # Target property
  TARGET_INDEX: 0  # First (and only) target after mixin replaces labels with CLogP
  TARGET_VALUE: 8.0
  TARGET_RELATIVE: false

  # Fingerprint parameters
  FINGERPRINT_TYPE: "morgan"
  FINGERPRINT_SIZE: 4096
  FINGERPRINT_RADIUS: 3

  # Model parameters (single model, no ensemble)
  HIDDEN_UNITS: [256, 256, 128]
  LEARNING_RATE: 0.001
  MAX_EPOCHS: 100
  BATCH_SIZE: 256
  USE_BEST_MODEL_RESTORER: true

  # Normalizing flow parameters
  USE_FLOW_CONSTRAINT: true
  FLOW_WEIGHT: 1.0
  FLOW_TYPE: "maf"  # Masked Autoregressive Flow works well for fingerprints
  FLOW_NUM_LAYERS: 8
  FLOW_HIDDEN_UNITS: 256
  FLOW_HIDDEN_LAYERS: 2
  FLOW_LEARNING_RATE: 0.001
  FLOW_EPOCHS: 100
  FLOW_BATCH_SIZE: 256
  FLOW_BASE_DIST: "gaussian"

  # Optimization parameters (no PCA)
  NUM_OPTIMIZATION_SAMPLES: 500
  OPTIMIZATION_EPOCHS: 200
  OPTIMIZATION_LEARNING_RATE: 0.1
  OPTIMIZATION_LEARNING_RATE_REDUCTION: 0.1
  ORIGINAL_DISTANCE_WEIGHT: 0.0
  DISTANCE_METRIC: "cosine"
  ENABLE_GRADIENT_CLIPPING: true
  TRAJECTORY_SAMPLING_INTERVAL: 10

  # Dataset splits
  NUM_TEST: 0.5
  NUM_TRAIN: 1.0
  NUM_VAL: 0.1

  # Visualization
  PLOT_INDIVIDUAL_TRAJECTORIES: true
  TRAJECTORY_FIGURE_SIZE: [21, 6]
